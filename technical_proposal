PROJECT PLAN
by Mike Ravella and Sawyer Thompson
mravella smt(<)3

General Description:
Real Time Rendering - Rendering will be done in a fragment shader in GLSL on a single quad.  The additional features that will be implemented include depth of field, skybox, ambient occlusion and refractions. We will also include functionality for rendering depth passes for use in the painterly rendering filter.  

Depth of field algo:
Assume the camera is an area instead of a point.  Use a specific t value as the depth of field of the camera.  Increase the area of the camera as we move further away from the desired t value.  Then jitter the camera position within the area of the disk to get the blurring.  Average the samples to get the blurred color. If this slows it down significantly, due to the large number of rays, we will output a depth pass and add blurring as a post effect in another frame buffer. 

Skybox:
Skybox will be implemented as a sphere instead of using the glsl skybox like from the labs.  This will essentially be implemented by surrounding the scene in a texture mapped sphere and sampling that sphere appropriately.

Ambient Occlusion:
Ambient occlusion will be implemented by shooting rays out from the hemisphere surrounding an intersection point, and giving them a cutoff distance.  Then we will just see how many of the rays intersect objects within their cutoff and essentially just computer number of intersections over number of rays.  

Refractions:
Refractions will be done quite similarly to reflections, except with using snells law to calculate directions of transmitted rays instead of just reflecting them.  We can also try to work in fresnel equations to make more realistic transmittance.

References:
My most common reference will probably be the glsl docs.
